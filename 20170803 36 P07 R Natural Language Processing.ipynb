{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/ggomarr/R/x86_64-pc-linux-gnu-library/3.3’\n",
      "(as ‘lib’ is unspecified)\n"
     ]
    }
   ],
   "source": [
    "# install.packages('tm')\n",
    "# install.packages(\"SnowballC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-12\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(caTools)\n",
    "library(ggplot2)\n",
    "library(repr)\n",
    "options(repr.plot.width=8,repr.plot.height=4)\n",
    "library(SnowballC)\n",
    "library(tm)\n",
    "library(e1071)\n",
    "library(rpart)\n",
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Review</th><th scope=col>Liked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Wow... Loved this place.                                                               </td><td>1                                                                                      </td></tr>\n",
       "\t<tr><td>Crust is not good.                                                                     </td><td>0                                                                                      </td></tr>\n",
       "\t<tr><td>Not tasty and the texture was just nasty.                                              </td><td>0                                                                                      </td></tr>\n",
       "\t<tr><td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td><td>1                                                                                      </td></tr>\n",
       "\t<tr><td>The selection on the menu was great and so were the prices.                            </td><td>1                                                                                      </td></tr>\n",
       "\t<tr><td>Now I am getting angry and I want my damn pho.                                         </td><td>0                                                                                      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Review & Liked\\\\\n",
       "\\hline\n",
       "\t Wow... Loved this place.                                                                & 1                                                                                      \\\\\n",
       "\t Crust is not good.                                                                      & 0                                                                                      \\\\\n",
       "\t Not tasty and the texture was just nasty.                                               & 0                                                                                      \\\\\n",
       "\t Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. & 1                                                                                      \\\\\n",
       "\t The selection on the menu was great and so were the prices.                             & 1                                                                                      \\\\\n",
       "\t Now I am getting angry and I want my damn pho.                                          & 0                                                                                      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Review | Liked | \n",
       "|---|---|---|---|---|---|\n",
       "| Wow... Loved this place.                                                                | 1                                                                                       | \n",
       "| Crust is not good.                                                                      | 0                                                                                       | \n",
       "| Not tasty and the texture was just nasty.                                               | 0                                                                                       | \n",
       "| Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. | 1                                                                                       | \n",
       "| The selection on the menu was great and so were the prices.                             | 1                                                                                       | \n",
       "| Now I am getting angry and I want my damn pho.                                          | 0                                                                                       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Review                                                                                 \n",
       "1 Wow... Loved this place.                                                               \n",
       "2 Crust is not good.                                                                     \n",
       "3 Not tasty and the texture was just nasty.                                              \n",
       "4 Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
       "5 The selection on the menu was great and so were the prices.                            \n",
       "6 Now I am getting angry and I want my damn pho.                                         \n",
       "  Liked\n",
       "1 1    \n",
       "2 0    \n",
       "3 0    \n",
       "4 1    \n",
       "5 1    \n",
       "6 0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_dir=\"~/Documents/Education/20170623 Udemy - Machine Learning A-Z: Hands-On Python and R in Data Science/\"\n",
    "work_dir=\"Course data/Part 7 - Natural Language Processing/Section 36 - Natural Language Processing\"\n",
    "setwd(paste(root_dir,work_dir,sep=''))\n",
    "df=read.csv('Restaurant_Reviews.tsv',sep='\\t',quote='',stringsAsFactors=FALSE)\n",
    "# df=read.delim('Restaurant_Reviews.tsv',quote='',stringsAsFactors=FALSE)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow... Loved this place.\n",
      "Crust is not good.\n",
      "Not tasty and the texture was just nasty.\n",
      "Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
      "The selection on the menu was great and so were the prices.\n",
      "Now I am getting angry and I want my damn pho.\n",
      "Honeslty it didn't taste THAT fresh.)\n",
      "The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\n",
      "The fries were great too.\n",
      "A great touch.\n"
     ]
    }
   ],
   "source": [
    "reviewCorpus=VCorpus(VectorSource(df$Review))\n",
    "writeLines(sapply(reviewCorpus[1:10],as.character))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processReview=function(review){\n",
    "    review=gsub('[^[:alpha:] ]','',review)\n",
    "#     review=removeNumbers(review)\n",
    "#     review=removePunctuation(review)\n",
    "    review=tolower(review)\n",
    "    review=removeWords(review,stopwords(\"english\"))\n",
    "    review=stemDocument(review)\n",
    "    review=stripWhitespace(review)\n",
    "    review\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow love place\n",
      "crust good\n",
      "tasti textur just nasti\n",
      "stop late may bank holiday rick steve recommend love\n",
      "select menu great price\n",
      "now get angri want damn pho\n",
      "honeslti didnt tast fresh\n",
      "potato like rubber tell made ahead time kept warmer\n",
      "fri great\n",
      "great touch\n"
     ]
    }
   ],
   "source": [
    "reviewCorpus=tm_map(reviewCorpus,content_transformer(processReview))\n",
    "writeLines(sapply(reviewCorpus[1:10],as.character))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<DocumentTermMatrix (documents: 1000, terms: 1577)>>\n",
      "Non-/sparse entries: 5435/1571565\n",
      "Sparsity           : 100%\n",
      "Maximal term length: 32\n",
      "Weighting          : term frequency (tf)\n",
      "Sample             :\n",
      "     Terms\n",
      "Docs  back food good great like place realli servic time will\n",
      "  124    0    0    0     0    0     1      0      0    0    0\n",
      "  133    0    1    1     0    0     0      0      0    0    0\n",
      "  158    0    0    0     0    0     0      1      0    1    0\n",
      "  237    0    0    0     0    0     0      0      0    0    0\n",
      "  29     0    2    0     0    1     0      0      0    0    0\n",
      "  43     0    0    1     0    0     0      0      0    0    0\n",
      "  534    0    1    0     0    0     1      0      0    0    0\n",
      "  716    0    0    0     1    0     0      0      0    0    0\n",
      "  863    0    1    0     0    0     0      0      0    0    0\n",
      "  885    0    0    0     0    0     0      0      0    1    0\n"
     ]
    }
   ],
   "source": [
    "X=DocumentTermMatrix(reviewCorpus)\n",
    "inspect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<DocumentTermMatrix (documents: 1000, terms: 691)>>\n",
      "Non-/sparse entries: 4549/686451\n",
      "Sparsity           : 99%\n",
      "Maximal term length: 12\n",
      "Weighting          : term frequency (tf)\n",
      "Sample             :\n",
      "     Terms\n",
      "Docs  back food good great like place realli servic time will\n",
      "  124    0    0    0     0    0     1      0      0    0    0\n",
      "  125    0    0    1     0    0     1      1      0    0    0\n",
      "  127    0    0    0     0    1     1      0      0    1    0\n",
      "  133    0    1    1     0    0     0      0      0    0    0\n",
      "  190    0    0    1     0    0     0      0      0    0    0\n",
      "  29     0    2    0     0    1     0      0      0    0    0\n",
      "  534    0    1    0     0    0     1      0      0    0    0\n",
      "  602    0    1    0     0    0     1      0      0    0    0\n",
      "  716    0    0    0     1    0     0      0      0    0    0\n",
      "  863    0    1    0     0    0     0      0      0    0    0\n"
     ]
    }
   ],
   "source": [
    "X=removeSparseTerms(X,0.999)\n",
    "inspect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>absolut</th><th scope=col>acknowledg</th><th scope=col>actual</th><th scope=col>ago</th><th scope=col>almost</th><th scope=col>also</th><th scope=col>although</th><th scope=col>alway</th><th scope=col>amaz</th><th scope=col>ambianc</th><th scope=col>⋯</th><th scope=col>wow</th><th scope=col>wrap</th><th scope=col>wrong</th><th scope=col>year</th><th scope=col>yet</th><th scope=col>youd</th><th scope=col>your</th><th scope=col>yummi</th><th scope=col>zero</th><th scope=col>Liked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " absolut & acknowledg & actual & ago & almost & also & although & alway & amaz & ambianc & ⋯ & wow & wrap & wrong & year & yet & youd & your & yummi & zero & Liked\\\\\n",
       "\\hline\n",
       "\t 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\\\\n",
       "\t 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "absolut | acknowledg | actual | ago | almost | also | although | alway | amaz | ambianc | ⋯ | wow | wrap | wrong | year | yet | youd | your | yummi | zero | Liked | \n",
       "|---|---|---|---|---|---|\n",
       "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | \n",
       "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | \n",
       "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | \n",
       "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | \n",
       "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | \n",
       "| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  absolut acknowledg actual ago almost also although alway amaz ambianc ⋯ wow\n",
       "1 0       0          0      0   0      0    0        0     0    0       ⋯ 1  \n",
       "2 0       0          0      0   0      0    0        0     0    0       ⋯ 0  \n",
       "3 0       0          0      0   0      0    0        0     0    0       ⋯ 0  \n",
       "4 0       0          0      0   0      0    0        0     0    0       ⋯ 0  \n",
       "5 0       0          0      0   0      0    0        0     0    0       ⋯ 0  \n",
       "6 0       0          0      0   0      0    0        0     0    0       ⋯ 0  \n",
       "  wrap wrong year yet youd your yummi zero Liked\n",
       "1 0    0     0    0   0    0    0     0    1    \n",
       "2 0    0     0    0   0    0    0     0    0    \n",
       "3 0    0     0    0   0    0    0     0    0    \n",
       "4 0    0     0    0   0    0    0     0    1    \n",
       "5 0    0     0    0   0    0    0     0    1    \n",
       "6 0    0     0    0   0    0    0     0    0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels=df$Liked\n",
    "df=as.data.frame(as.matrix(X))\n",
    "df$Liked=factor(labels,levels=c(0,1))\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training set: 800x692\n",
      "[1] Test set: 200x692\n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "split=sample.split(df$Liked, SplitRatio=0.8)\n",
    "training_set=subset(df,split)\n",
    "test_set=subset(df,!split)\n",
    "print(noquote(paste('Training set:',paste(dim(training_set),collapse='x'))))\n",
    "print(noquote(paste('Test set:',paste(dim(test_set),collapse='x'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive Bayes ===\n",
      "\n",
      "Classifier summary:\n",
      "        Length Class  Mode     \n",
      "apriori   2    table  numeric  \n",
      "tables  691    -none- list     \n",
      "levels    2    -none- character\n",
      "call      4    -none- call     \n",
      "\n",
      "Confusion matrix:\n",
      "   y_pred\n",
      "     0  1\n",
      "  0  5 95\n",
      "  1  4 96\n"
     ]
    }
   ],
   "source": [
    "writeLines('\\n=== Naive Bayes ===')\n",
    "my_classifier=naiveBayes(formula=Liked~.,data=training_set)\n",
    "writeLines('\\nClassifier summary:')\n",
    "print(summary(my_classifier))\n",
    "y_pred=predict(my_classifier,newdata=test_set)\n",
    "writeLines('\\nConfusion matrix:')\n",
    "print(table(test_set$Liked,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree ===\n",
      "\n",
      "Classifier summary:\n",
      "Call:\n",
      "rpart(formula = Liked ~ ., data = training_set, method = \"class\", \n",
      "    control = rpart.control(minsplit = 1))\n",
      "  n= 800 \n",
      "\n",
      "           CP nsplit rel error xerror       xstd\n",
      "1  0.12750000      0    1.0000 1.0650 0.03528057\n",
      "2  0.08500000      1    0.8725 0.9125 0.03521973\n",
      "3  0.04500000      2    0.7875 0.7875 0.03454786\n",
      "4  0.03750000      4    0.6975 0.7250 0.03399219\n",
      "5  0.02750000      5    0.6600 0.6750 0.03343604\n",
      "6  0.02500000      7    0.6050 0.6400 0.03298485\n",
      "7  0.01833333      8    0.5800 0.6075 0.03251814\n",
      "8  0.01750000     11    0.5250 0.6050 0.03248028\n",
      "9  0.01250000     12    0.5075 0.5625 0.03179217\n",
      "10 0.01000000     13    0.4950 0.5375 0.03134673\n",
      "\n",
      "Variable importance\n",
      "    great      good    delici      love      amaz      nice   fantast   perfect \n",
      "       21        10         9         8         8         6         6         5 \n",
      "   awesom      best    friend      vega      feel highlight      wall  eggplant \n",
      "        5         5         4         4         3         1         1         1 \n",
      "     char     staff      roll \n",
      "        1         1         1 \n",
      "\n",
      "Node number 1: 800 observations,    complexity param=0.1275\n",
      "  predicted class=0  expected loss=0.5  P(node) =1\n",
      "    class counts:   400   400\n",
      "   probabilities: 0.500 0.500 \n",
      "  left son=2 (749 obs) right son=3 (51 obs)\n",
      "  Primary splits:\n",
      "      great  < 0.5 to the left,  improve=27.236320, (0 missing)\n",
      "      good   < 0.5 to the left,  improve=10.856680, (0 missing)\n",
      "      delici < 0.5 to the left,  improve=10.256410, (0 missing)\n",
      "      love   < 0.5 to the left,  improve= 8.451919, (0 missing)\n",
      "      dont   < 0.5 to the right, improve= 7.950706, (0 missing)\n",
      "  Surrogate splits:\n",
      "      highlight < 0.5 to the left,  agree=0.939, adj=0.039, (0 split)\n",
      "      wall      < 0.5 to the left,  agree=0.939, adj=0.039, (0 split)\n",
      "      beauti    < 0.5 to the left,  agree=0.938, adj=0.020, (0 split)\n",
      "\n",
      "Node number 2: 749 observations,    complexity param=0.085\n",
      "  predicted class=0  expected loss=0.4659546  P(node) =0.93625\n",
      "    class counts:   400   349\n",
      "   probabilities: 0.534 0.466 \n",
      "  left son=4 (683 obs) right son=5 (66 obs)\n",
      "  Primary splits:\n",
      "      good   < 0.5 to the left,  improve=12.310430, (0 missing)\n",
      "      delici < 0.5 to the left,  improve=11.119850, (0 missing)\n",
      "      love   < 0.5 to the left,  improve= 9.442161, (0 missing)\n",
      "      amaz   < 0.5 to the left,  improve= 7.742560, (0 missing)\n",
      "      dont   < 0.5 to the right, improve= 6.620585, (0 missing)\n",
      "  Surrogate splits:\n",
      "      compani    < 0.5 to the left,  agree=0.915, adj=0.030, (0 split)\n",
      "      flavorless < 0.5 to the left,  agree=0.915, adj=0.030, (0 split)\n",
      "      stuff      < 0.5 to the left,  agree=0.915, adj=0.030, (0 split)\n",
      "      melt       < 0.5 to the left,  agree=0.913, adj=0.015, (0 split)\n",
      "      real       < 0.5 to the left,  agree=0.913, adj=0.015, (0 split)\n",
      "\n",
      "Node number 3: 51 observations\n",
      "  predicted class=1  expected loss=0  P(node) =0.06375\n",
      "    class counts:     0    51\n",
      "   probabilities: 0.000 1.000 \n",
      "\n",
      "Node number 4: 683 observations,    complexity param=0.045\n",
      "  predicted class=0  expected loss=0.4377745  P(node) =0.85375\n",
      "    class counts:   384   299\n",
      "   probabilities: 0.562 0.438 \n",
      "  left son=8 (665 obs) right son=9 (18 obs)\n",
      "  Primary splits:\n",
      "      delici  < 0.5 to the left,  improve=11.687530, (0 missing)\n",
      "      love    < 0.5 to the left,  improve=10.793550, (0 missing)\n",
      "      amaz    < 0.5 to the left,  improve=10.150440, (0 missing)\n",
      "      fantast < 0.5 to the left,  improve= 7.067977, (0 missing)\n",
      "      nice    < 0.5 to the left,  improve= 7.002237, (0 missing)\n",
      "\n",
      "Node number 5: 66 observations\n",
      "  predicted class=1  expected loss=0.2424242  P(node) =0.0825\n",
      "    class counts:    16    50\n",
      "   probabilities: 0.242 0.758 \n",
      "\n",
      "Node number 8: 665 observations,    complexity param=0.045\n",
      "  predicted class=0  expected loss=0.4225564  P(node) =0.83125\n",
      "    class counts:   384   281\n",
      "   probabilities: 0.577 0.423 \n",
      "  left son=16 (641 obs) right son=17 (24 obs)\n",
      "  Primary splits:\n",
      "      love    < 0.5 to the left,  improve=10.193750, (0 missing)\n",
      "      amaz    < 0.5 to the left,  improve=10.078010, (0 missing)\n",
      "      nice    < 0.5 to the left,  improve= 7.534936, (0 missing)\n",
      "      fantast < 0.5 to the left,  improve= 7.459088, (0 missing)\n",
      "      awesom  < 0.5 to the left,  improve= 5.400021, (0 missing)\n",
      "  Surrogate splits:\n",
      "      eggplant < 0.5 to the left,  agree=0.967, adj=0.083, (0 split)\n",
      "      bean     < 0.5 to the left,  agree=0.965, adj=0.042, (0 split)\n",
      "\n",
      "Node number 9: 18 observations\n",
      "  predicted class=1  expected loss=0  P(node) =0.0225\n",
      "    class counts:     0    18\n",
      "   probabilities: 0.000 1.000 \n",
      "\n",
      "Node number 16: 641 observations,    complexity param=0.0375\n",
      "  predicted class=0  expected loss=0.4056162  P(node) =0.80125\n",
      "    class counts:   381   260\n",
      "   probabilities: 0.594 0.406 \n",
      "  left son=32 (624 obs) right son=33 (17 obs)\n",
      "  Primary splits:\n",
      "      amaz    < 0.5 to the left,  improve=10.017720, (0 missing)\n",
      "      fantast < 0.5 to the left,  improve= 7.177820, (0 missing)\n",
      "      nice    < 0.5 to the left,  improve= 6.776192, (0 missing)\n",
      "      awesom  < 0.5 to the left,  improve= 5.724113, (0 missing)\n",
      "      perfect < 0.5 to the left,  improve= 5.000699, (0 missing)\n",
      "\n",
      "Node number 17: 24 observations\n",
      "  predicted class=1  expected loss=0.125  P(node) =0.03\n",
      "    class counts:     3    21\n",
      "   probabilities: 0.125 0.875 \n",
      "\n",
      "Node number 32: 624 observations,    complexity param=0.0275\n",
      "  predicted class=0  expected loss=0.3910256  P(node) =0.78\n",
      "    class counts:   380   244\n",
      "   probabilities: 0.609 0.391 \n",
      "  left son=64 (614 obs) right son=65 (10 obs)\n",
      "  Primary splits:\n",
      "      fantast < 0.5 to the left,  improve=7.537793, (0 missing)\n",
      "      nice    < 0.5 to the left,  improve=7.252094, (0 missing)\n",
      "      awesom  < 0.5 to the left,  improve=5.250800, (0 missing)\n",
      "      perfect < 0.5 to the left,  improve=5.250800, (0 missing)\n",
      "      best    < 0.5 to the left,  improve=5.156533, (0 missing)\n",
      "  Surrogate splits:\n",
      "      roll < 0.5 to the left,  agree=0.986, adj=0.1, (0 split)\n",
      "\n",
      "Node number 33: 17 observations\n",
      "  predicted class=1  expected loss=0.05882353  P(node) =0.02125\n",
      "    class counts:     1    16\n",
      "   probabilities: 0.059 0.941 \n",
      "\n",
      "Node number 64: 614 observations,    complexity param=0.0275\n",
      "  predicted class=0  expected loss=0.3811075  P(node) =0.7675\n",
      "    class counts:   380   234\n",
      "   probabilities: 0.619 0.381 \n",
      "  left son=128 (596 obs) right son=129 (18 obs)\n",
      "  Primary splits:\n",
      "      nice    < 0.5 to the left,  improve=7.584647, (0 missing)\n",
      "      best    < 0.5 to the left,  improve=5.468475, (0 missing)\n",
      "      friend  < 0.5 to the left,  improve=5.468475, (0 missing)\n",
      "      awesom  < 0.5 to the left,  improve=5.424231, (0 missing)\n",
      "      perfect < 0.5 to the left,  improve=5.424231, (0 missing)\n",
      "  Surrogate splits:\n",
      "      char < 0.5 to the left,  agree=0.974, adj=0.111, (0 split)\n",
      "\n",
      "Node number 65: 10 observations\n",
      "  predicted class=1  expected loss=0  P(node) =0.0125\n",
      "    class counts:     0    10\n",
      "   probabilities: 0.000 1.000 \n",
      "\n",
      "Node number 128: 596 observations,    complexity param=0.025\n",
      "  predicted class=0  expected loss=0.3674497  P(node) =0.745\n",
      "    class counts:   377   219\n",
      "   probabilities: 0.633 0.367 \n",
      "  left son=256 (574 obs) right son=257 (22 obs)\n",
      "  Primary splits:\n",
      "      best    < 0.5 to the left,  improve=5.915140, (0 missing)\n",
      "      vega    < 0.5 to the left,  improve=5.757908, (0 missing)\n",
      "      awesom  < 0.5 to the left,  improve=5.668252, (0 missing)\n",
      "      perfect < 0.5 to the left,  improve=5.668252, (0 missing)\n",
      "      friend  < 0.5 to the left,  improve=5.236923, (0 missing)\n",
      "  Surrogate splits:\n",
      "      phoenix < 0.5 to the left,  agree=0.965, adj=0.045, (0 split)\n",
      "\n",
      "Node number 129: 18 observations\n",
      "  predicted class=1  expected loss=0.1666667  P(node) =0.0225\n",
      "    class counts:     3    15\n",
      "   probabilities: 0.167 0.833 \n",
      "\n",
      "Node number 256: 574 observations,    complexity param=0.01833333\n",
      "  predicted class=0  expected loss=0.3536585  P(node) =0.7175\n",
      "    class counts:   371   203\n",
      "   probabilities: 0.646 0.354 \n",
      "  left son=512 (567 obs) right son=513 (7 obs)\n",
      "  Primary splits:\n",
      "      awesom  < 0.5 to the left,  improve=5.920807, (0 missing)\n",
      "      perfect < 0.5 to the left,  improve=5.920807, (0 missing)\n",
      "      happi   < 0.5 to the left,  improve=5.066043, (0 missing)\n",
      "      friend  < 0.5 to the left,  improve=4.971313, (0 missing)\n",
      "      vega    < 0.5 to the left,  improve=4.594258, (0 missing)\n",
      "\n",
      "Node number 257: 22 observations\n",
      "  predicted class=1  expected loss=0.2727273  P(node) =0.0275\n",
      "    class counts:     6    16\n",
      "   probabilities: 0.273 0.727 \n",
      "\n",
      "Node number 512: 567 observations,    complexity param=0.01833333\n",
      "  predicted class=0  expected loss=0.345679  P(node) =0.70875\n",
      "    class counts:   371   196\n",
      "   probabilities: 0.654 0.346 \n",
      "  left son=1024 (560 obs) right son=1025 (7 obs)\n",
      "  Primary splits:\n",
      "      perfect < 0.5 to the left,  improve=6.068827, (0 missing)\n",
      "      friend  < 0.5 to the left,  improve=5.205345, (0 missing)\n",
      "      happi   < 0.5 to the left,  improve=5.192579, (0 missing)\n",
      "      vega    < 0.5 to the left,  improve=4.773749, (0 missing)\n",
      "      dont    < 0.5 to the right, improve=4.126021, (0 missing)\n",
      "\n",
      "Node number 513: 7 observations\n",
      "  predicted class=1  expected loss=0  P(node) =0.00875\n",
      "    class counts:     0     7\n",
      "   probabilities: 0.000 1.000 \n",
      "\n",
      "Node number 1024: 560 observations,    complexity param=0.01833333\n",
      "  predicted class=0  expected loss=0.3375  P(node) =0.7\n",
      "    class counts:   371   189\n",
      "   probabilities: 0.663 0.338 \n",
      "  left son=2048 (540 obs) right son=2049 (20 obs)\n",
      "  Primary splits:\n",
      "      friend < 0.5 to the left,  improve=5.450926, (0 missing)\n",
      "      happi  < 0.5 to the left,  improve=5.323917, (0 missing)\n",
      "      vega   < 0.5 to the left,  improve=4.961352, (0 missing)\n",
      "      dont   < 0.5 to the right, improve=3.906244, (0 missing)\n",
      "      feel   < 0.5 to the left,  improve=3.828255, (0 missing)\n",
      "  Surrogate splits:\n",
      "      staff    < 0.5 to the left,  agree=0.970, adj=0.15, (0 split)\n",
      "      super    < 0.5 to the left,  agree=0.968, adj=0.10, (0 split)\n",
      "      help     < 0.5 to the left,  agree=0.966, adj=0.05, (0 split)\n",
      "      waitress < 0.5 to the left,  agree=0.966, adj=0.05, (0 split)\n",
      "\n",
      "Node number 1025: 7 observations\n",
      "  predicted class=1  expected loss=0  P(node) =0.00875\n",
      "    class counts:     0     7\n",
      "   probabilities: 0.000 1.000 \n",
      "\n",
      "Node number 2048: 540 observations,    complexity param=0.0175\n",
      "  predicted class=0  expected loss=0.3240741  P(node) =0.675\n",
      "    class counts:   365   175\n",
      "   probabilities: 0.676 0.324 \n",
      "  left son=4096 (527 obs) right son=4097 (13 obs)\n",
      "  Primary splits:\n",
      "      vega  < 0.5 to the left,  improve=5.279373, (0 missing)\n",
      "      happi < 0.5 to the left,  improve=4.611457, (0 missing)\n",
      "      feel  < 0.5 to the left,  improve=4.030520, (0 missing)\n",
      "      fun   < 0.5 to the left,  improve=3.682283, (0 missing)\n",
      "      spot  < 0.5 to the left,  improve=3.682283, (0 missing)\n",
      "  Surrogate splits:\n",
      "      trip < 0.5 to the left,  agree=0.978, adj=0.077, (0 split)\n",
      "\n",
      "Node number 2049: 20 observations\n",
      "  predicted class=1  expected loss=0.3  P(node) =0.025\n",
      "    class counts:     6    14\n",
      "   probabilities: 0.300 0.700 \n",
      "\n",
      "Node number 4096: 527 observations,    complexity param=0.0125\n",
      "  predicted class=0  expected loss=0.313093  P(node) =0.65875\n",
      "    class counts:   362   165\n",
      "   probabilities: 0.687 0.313 \n",
      "  left son=8192 (520 obs) right son=8193 (7 obs)\n",
      "  Primary splits:\n",
      "      feel   < 0.5 to the left,  improve=4.199647, (0 missing)\n",
      "      fun    < 0.5 to the left,  improve=3.803600, (0 missing)\n",
      "      happi  < 0.5 to the left,  improve=3.803600, (0 missing)\n",
      "      wonder < 0.5 to the left,  improve=3.803600, (0 missing)\n",
      "      dont   < 0.5 to the right, improve=3.289038, (0 missing)\n",
      "\n",
      "Node number 4097: 13 observations\n",
      "  predicted class=1  expected loss=0.2307692  P(node) =0.01625\n",
      "    class counts:     3    10\n",
      "   probabilities: 0.231 0.769 \n",
      "\n",
      "Node number 8192: 520 observations\n",
      "  predicted class=0  expected loss=0.3057692  P(node) =0.65\n",
      "    class counts:   361   159\n",
      "   probabilities: 0.694 0.306 \n",
      "\n",
      "Node number 8193: 7 observations\n",
      "  predicted class=1  expected loss=0.1428571  P(node) =0.00875\n",
      "    class counts:     1     6\n",
      "   probabilities: 0.143 0.857 \n",
      "\n",
      "n= 800 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      "   1) root 800 400 0 (0.50000000 0.50000000)  \n",
      "     2) great< 0.5 749 349 0 (0.53404539 0.46595461)  \n",
      "       4) good< 0.5 683 299 0 (0.56222548 0.43777452)  \n",
      "         8) delici< 0.5 665 281 0 (0.57744361 0.42255639)  \n",
      "          16) love< 0.5 641 260 0 (0.59438378 0.40561622)  \n",
      "            32) amaz< 0.5 624 244 0 (0.60897436 0.39102564)  \n",
      "              64) fantast< 0.5 614 234 0 (0.61889251 0.38110749)  \n",
      "               128) nice< 0.5 596 219 0 (0.63255034 0.36744966)  \n",
      "                 256) best< 0.5 574 203 0 (0.64634146 0.35365854)  \n",
      "                   512) awesom< 0.5 567 196 0 (0.65432099 0.34567901)  \n",
      "                    1024) perfect< 0.5 560 189 0 (0.66250000 0.33750000)  \n",
      "                      2048) friend< 0.5 540 175 0 (0.67592593 0.32407407)  \n",
      "                        4096) vega< 0.5 527 165 0 (0.68690702 0.31309298)  \n",
      "                          8192) feel< 0.5 520 159 0 (0.69423077 0.30576923) *\n",
      "                          8193) feel>=0.5 7   1 1 (0.14285714 0.85714286) *\n",
      "                        4097) vega>=0.5 13   3 1 (0.23076923 0.76923077) *\n",
      "                      2049) friend>=0.5 20   6 1 (0.30000000 0.70000000) *\n",
      "                    1025) perfect>=0.5 7   0 1 (0.00000000 1.00000000) *\n",
      "                   513) awesom>=0.5 7   0 1 (0.00000000 1.00000000) *\n",
      "                 257) best>=0.5 22   6 1 (0.27272727 0.72727273) *\n",
      "               129) nice>=0.5 18   3 1 (0.16666667 0.83333333) *\n",
      "              65) fantast>=0.5 10   0 1 (0.00000000 1.00000000) *\n",
      "            33) amaz>=0.5 17   1 1 (0.05882353 0.94117647) *\n",
      "          17) love>=0.5 24   3 1 (0.12500000 0.87500000) *\n",
      "         9) delici>=0.5 18   0 1 (0.00000000 1.00000000) *\n",
      "       5) good>=0.5 66  16 1 (0.24242424 0.75757576) *\n",
      "     3) great>=0.5 51   0 1 (0.00000000 1.00000000) *\n",
      "\n",
      "Confusion matrix:\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 85 15\n",
      "  1 43 57\n"
     ]
    }
   ],
   "source": [
    "writeLines('\\n=== Decision Tree ===')\n",
    "my_classifier=rpart(formula=Liked~.,data=training_set,\n",
    "                    method='class',control=rpart.control(minsplit=1))\n",
    "writeLines('\\nClassifier summary:')\n",
    "print(summary(my_classifier))\n",
    "y_pred=predict(my_classifier,newdata=test_set,type='class')\n",
    "writeLines('\\nConfusion matrix:')\n",
    "print(table(test_set$Liked,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest, 10 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forests, 10 trees ===\n",
      "\n",
      "Classifier summary:\n",
      "                Length Class  Mode     \n",
      "call               4   -none- call     \n",
      "type               1   -none- character\n",
      "predicted        800   factor numeric  \n",
      "err.rate          30   -none- numeric  \n",
      "confusion          6   -none- numeric  \n",
      "votes           1600   matrix numeric  \n",
      "oob.times        800   -none- numeric  \n",
      "classes            2   -none- character\n",
      "importance       691   -none- numeric  \n",
      "importanceSD       0   -none- NULL     \n",
      "localImportance    0   -none- NULL     \n",
      "proximity          0   -none- NULL     \n",
      "ntree              1   -none- numeric  \n",
      "mtry               1   -none- numeric  \n",
      "forest            14   -none- list     \n",
      "y                800   factor numeric  \n",
      "test               0   -none- NULL     \n",
      "inbag              0   -none- NULL     \n",
      "\n",
      "Confusion matrix:\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 76 24\n",
      "  1 23 77\n"
     ]
    }
   ],
   "source": [
    "name='Random Forests, 10 trees'\n",
    "writeLines(paste('\\n===',name,'==='))\n",
    "my_classifier=randomForest(x=training_set[,!(colnames(training_set)=='Liked')],y=training_set$Liked,ntree=10)\n",
    "writeLines('\\nClassifier summary:')\n",
    "print(summary(my_classifier))\n",
    "y_pred=predict(my_classifier,newdata=test_set,type='class')\n",
    "writeLines('\\nConfusion matrix:')\n",
    "print(table(test_set$Liked,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Random Forest, 100 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forests, 100 trees ===\n",
      "\n",
      "Classifier summary:\n",
      "                Length Class  Mode     \n",
      "call               4   -none- call     \n",
      "type               1   -none- character\n",
      "predicted        800   factor numeric  \n",
      "err.rate         300   -none- numeric  \n",
      "confusion          6   -none- numeric  \n",
      "votes           1600   matrix numeric  \n",
      "oob.times        800   -none- numeric  \n",
      "classes            2   -none- character\n",
      "importance       691   -none- numeric  \n",
      "importanceSD       0   -none- NULL     \n",
      "localImportance    0   -none- NULL     \n",
      "proximity          0   -none- NULL     \n",
      "ntree              1   -none- numeric  \n",
      "mtry               1   -none- numeric  \n",
      "forest            14   -none- list     \n",
      "y                800   factor numeric  \n",
      "test               0   -none- NULL     \n",
      "inbag              0   -none- NULL     \n",
      "\n",
      "Confusion matrix:\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 74 26\n",
      "  1 21 79\n"
     ]
    }
   ],
   "source": [
    "name='Random Forests, 100 trees'\n",
    "writeLines(paste('\\n===',name,'==='))\n",
    "my_classifier=randomForest(x=training_set[,!(colnames(training_set)=='Liked')],y=training_set$Liked,ntree=100)\n",
    "writeLines('\\nClassifier summary:')\n",
    "print(summary(my_classifier))\n",
    "y_pred=predict(my_classifier,newdata=test_set,type='class')\n",
    "writeLines('\\nConfusion matrix:')\n",
    "print(table(test_set$Liked,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
